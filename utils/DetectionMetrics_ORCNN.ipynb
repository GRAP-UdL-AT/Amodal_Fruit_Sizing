{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the detection metrics of ORCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to restart your runtime prior to this, to let your installation take effect\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "from numpy.linalg import inv\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import tifffile\n",
    "from pyexcel_ods import get_data\n",
    "import csv\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import circle_fit as cf\n",
    "\n",
    "# import some miscellaneous libraries\n",
    "import visualize\n",
    "import statistics\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog,MetadataCatalog\n",
    "from detectron2.engine import DefaultTrainer\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "pylab.rcParams['figure.figsize'] = 10,10\n",
    "\n",
    "def imshow(img):\n",
    "    plt.imshow(img[:, :, [2, 1, 0]])\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the visible dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "maindir = os.path.dirname(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"broccoli_amodal_test\", {}, maindir + \"/datasets/train_val_test_files/orcnn/test/annotations.json\", maindir + \"/datasets/train_val_test_files/orcnn/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata(evaluator_type='coco', image_root='/home/pieterdeeplearn/harvestcnn/datasets/train_val_test_files/orcnn/test', json_file='/home/pieterdeeplearn/harvestcnn/datasets/train_val_test_files/orcnn/test/annotations.json', name='broccoli_amodal_test')\n"
     ]
    }
   ],
   "source": [
    "broccoli_amodal_test_metadata = MetadataCatalog.get(\"broccoli_amodal_test\")\n",
    "print(broccoli_amodal_test_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/08 16:58:13 d2.data.datasets.coco]: \u001b[0mLoaded 487 images in COCO format from /home/pieterdeeplearn/harvestcnn/datasets/train_val_test_files/orcnn/test/annotations.json\n"
     ]
    }
   ],
   "source": [
    "dataset_dicts_test = DatasetCatalog.get(\"broccoli_amodal_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the image inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_orcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (broccoli)\n",
    "\n",
    "cfg.OUTPUT_DIR = \"weights/20201109_broccoli_amodal_visible\"\n",
    "cfg.MODEL.WEIGHTS = os.path.join(maindir, cfg.OUTPUT_DIR, \"model_0007999.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.01\n",
    "cfg.DATASETS.TEST = (\"broccoli_amodal_test\",)\n",
    "\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the detection metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input needed (directory, file locations, etc):\n",
    "analysis_name = \"orcnn_detection_metrics\"\n",
    "gtfile = os.path.join(maindir, \"datasets/train_val_test_files/groundtruth_measurements_broccoli.ods\") ## comment out if there is no ground truth file (also restart the kernel)\n",
    "IoU_thres = 0.5\n",
    "visualize_output = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 487/487 [01:14<00:00,  6.54it/s]\n"
     ]
    }
   ],
   "source": [
    "writedir = os.path.join(maindir, \"results\")\n",
    "\n",
    "if not os.path.exists(writedir):\n",
    "    os.makedirs(writedir)\n",
    "\n",
    "try:\n",
    "    gt = get_data(gtfile)\n",
    "    gt_file_present = True\n",
    "except:\n",
    "    gt_file_present = False\n",
    "\n",
    "csv_name = analysis_name + '.csv'\n",
    "with open(os.path.join(writedir, csv_name), 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    csvwriter.writerow(['image_id', 'number of gt masks', 'number of detected masks', 'number of true positives', 'number of false positives', 'number of false negatives', 'true positive on measured broccoli', 'false positive on measured broccoli', 'false negative on measured broccoli'])\n",
    "\n",
    "ids_visualize = np.random.choice(np.arange(len(dataset_dicts_test)), 10)\n",
    "random_images = []\n",
    "random_imagenames = []\n",
    "\n",
    "for i in tqdm(range(len(dataset_dicts_test))):\n",
    "    \n",
    "    # Load the RGB image\n",
    "    imgname = dataset_dicts_test[i][\"file_name\"]\n",
    "    basename = os.path.basename(imgname)\n",
    "    img = cv2.imread(imgname)\n",
    "\n",
    "\n",
    "    # Do the image inference and extract the outputs from Mask R-CNN\n",
    "    outputs = predictor(img)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "    classes = instances.pred_classes.numpy()\n",
    "    scores = instances.scores.numpy()\n",
    "    boxes = instances.pred_boxes.tensor.numpy()\n",
    "    try:\n",
    "        detection_num = len(boxes)\n",
    "    except:\n",
    "        detection_num = 0\n",
    "\n",
    "\n",
    "    # Procedure to check whether we are dealing with ORCNN or MRCNN\n",
    "    if \"pred_visible_masks\" in instances._fields:\n",
    "        amodal_masks = instances.pred_masks.numpy()\n",
    "        visible_masks = instances.pred_visible_masks.numpy()\n",
    "    else:\n",
    "        visible_masks = instances.pred_masks.numpy()\n",
    "\n",
    "\n",
    "    # Visualize the masks\n",
    "    if visualize_output:\n",
    "        visualizer = Visualizer(img[:, :, ::-1], metadata=broccoli_visible_test_metadata, scale=0.8)\n",
    "        vis = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        imshow(vis.get_image()[:, :, ::-1])\n",
    "\n",
    "\n",
    "    # Procedure to load the annotations (to calculate the amodal and the visible IoU)\n",
    "    d = dataset_dicts_test[i]\n",
    "    classes_annot = []\n",
    "    amodal_masks_poly = []\n",
    "    visible_masks_poly = []\n",
    "    for k in range(len(d[\"annotations\"])):\n",
    "        classes_annot.append(d[\"annotations\"][k]['category_id'])\n",
    "        amodal_masks_poly.append(d[\"annotations\"][k]['segmentation'])\n",
    "        visible_masks_poly.append(d[\"annotations\"][k]['visible_mask'])\n",
    "\n",
    "\n",
    "    # Calculate the visible IoU    \n",
    "    visible_masks_annot = visualize.make_mask_img(visible_masks_poly, d['height'], d['width'], \"polylines\")\n",
    "    gt_num = visible_masks_annot.shape[0]\n",
    "    iou_visible = statistics.calculate_iou(visible_masks_annot, visible_masks, np.array(classes_annot), classes)\n",
    "    max_iou_visible = np.amax(iou_visible, axis=0)\n",
    "\n",
    "\n",
    "    # Calculate the detection metrics\n",
    "    TPs = np.where(max_iou_visible >= IoU_thres)[0].shape[0]\n",
    "    FPs = detection_num - TPs\n",
    "    FNs = gt_num - TPs\n",
    "    \n",
    "    \n",
    "    # Calculate the detection metrics only on the measured broccoli heads\n",
    "    gt_data_present = False\n",
    "\n",
    "    if gt_file_present:\n",
    "        for k in range(1, len(gt['groundtruth_measurements_broccoli'])):\n",
    "            gt_data = gt['groundtruth_measurements_broccoli'][k]\n",
    "            if gt_data:\n",
    "                if gt_data[0] == basename:\n",
    "                    gt_data_present = True\n",
    "                    plant_id = gt_data[1]\n",
    "                    x_center_gt = gt_data[3]\n",
    "                    y_center_gt = gt_data[4]\n",
    "                    coordinates_broccoli_gt = (x_center_gt, y_center_gt)\n",
    "\n",
    "\n",
    "    # Find the broccoli head that belongs to the ground truth data\n",
    "    distances = []\n",
    "    if np.logical_and(boxes.size > 0, gt_data_present):\n",
    "        for h in range(len(boxes)):\n",
    "            box = boxes[h]\n",
    "            x_center = box[0] + ((box[2] - box[0]) / 2)\n",
    "            y_center = box[1] + ((box[3] - box[1]) / 2)\n",
    "            distances.append(np.linalg.norm(np.asarray(coordinates_broccoli_gt) - np.asarray((x_center, y_center))))\n",
    "\n",
    "        idx = np.asarray(distances).argmin()\n",
    "        visible_IoU = max_iou_visible[idx]\n",
    "    else:\n",
    "        idx = []\n",
    "        visible_IoU = np.nan\n",
    "\n",
    "        \n",
    "    # Calculate the detection metrics\n",
    "    TP_broc = np.where(visible_IoU >= IoU_thres)[0].shape[0]\n",
    "    FP_broc = 1 - TP_broc\n",
    "    FN_broc = 1 - TP_broc\n",
    "    \n",
    "    \n",
    "    # Store the results\n",
    "    with open(os.path.join(writedir, csv_name), 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        csvwriter.writerow([basename, gt_num, detection_num, TPs, FPs, FNs, TP_broc, FP_broc, FN_broc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
